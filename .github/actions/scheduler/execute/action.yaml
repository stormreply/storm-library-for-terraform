name: Execute

inputs:
  backend_bucket:
    required: true

runs:
  using: composite
  steps:

    - name: Execute
      shell: bash
      run: |
        # Execute

        for e in $(cat /tmp/selected) ; do

          file=${e##*/} ; f=${file}
          date=${f%%-*} ; f=${f##$date-}
          time=${f%%-*} ; f=${f##$time-}
          action=${f%%-*} ; f=${f##$action-}
          account_id=${f%%-*} ; f=${f##$account_id-}
          region=${f%-${f#*-*-*-}} ; f=${f##$region-}
          slt=${f%%-*} ; f=${f##$slt-}
          catalog_id=${f%%-*} ; f=${f##$catalog_id-}
          repo=${f%-*}
          environment=${f##$repo-}

          aws s3 cp ${timestamp} s3://${inputs.backend_bucket}/schedule/$file /tmp

          # cat << EOF
          # EXECUTE
          #   cat /tmp/$file
          #   | gh workflow run ${action}.yaml --field environment=${environment} --repo stormreply/${repo}
          # EOF

          # TODO: handle "stormreply": put into yaml in s3 object itself, together with tfvars name
          cat /tmp/$file | gh workflow run ${action}.yaml --json --repo stormreply/${repo} &

        done
